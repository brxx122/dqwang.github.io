---
layout: page-head
permalink: /publications/
title: Publications
---

<!-- Full publication list can be found in [Google Scholar](https://scholar.google.com/citations?hl=zh-CN&user=mAo_lUwAAAAJ). -->

My research focuses on:
- **Large Language Models**: More Intelligent, More Personalized, More Collaborative<a href="#llm" style="text-decoration:none;"> Go <i class="fas fa-arrow-right"></i></a>
- **AI for Drug**: How to find new drugs and interprete AI-decision?<a href="#drug" style="text-decoration:none;"> Go <i class="fas fa-arrow-right"></i></a>
- **Text Summarization**: Compression is intelligence! Concise & Faithful & Multilingual <a href="#summ" style="text-decoration:none;"> Go <i class="fas fa-arrow-right"></i></a>


<!-- Add buttons here -->
<div class="btn-group" role="group" aria-label="Sort Options">
  <a href="years"><i class="fas fa-calendar-alt"></i> Sorted by Year</a>
  <a href="tags"><i class="fas fa-tags"></i> Sorted by Tags</a>
  <!-- <a href="confs"><i class="fas fa-graduation-cap"></i> Sorted by Conference</a> -->
</div>

<h2 id="llm"><i>Large Language Models: More Intelligent, More Personalized, More Collaborative</i></h2> 
<!-- <details>
<summary><i><ins>More Intelligent, More Personalized, More Collaborative</ins></i></summary>    -->
<!-- <i><ins>More Intelligent, More Personalized, More Collaborative</ins></i> -->
<a href="#" onclick="backToTop()" class="back-to-top">Top &#8648;</a>

  <table>
  <tr>
    <td width="65%">
      <h4>
        Cooperative Strategic Planning Enhances Reasoning Capabilities in Large Language Models
        <a href="https://arxiv.org/abs/2410.20007"><i class="fa fa-link fa-sm"></i></a>
        <!-- <a href=""><i class="fa fa-home"></i></a> -->
      </h4>
      <em><strong>Danqing Wang</strong></em>, Zhuorui Ye, Fei Fang, Lei Li <br/>
      <!-- <em>arXiv preprint, 2024</em> -->
      <em>Under submission</em>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/CoPlanner.jpg" alt="CoPlanner"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        TypedThinker: Typed Thinking Improves Large Language Model Reasoning
        <a href="https://arxiv.org/abs/2410.01952"><i class="fa fa-link fa-sm"></i></a>
        <!-- <a href=""><i class="fa fa-home"></i></a> -->
      </h4>
      <em><strong>Danqing Wang</strong></em>, JianXin Ma, Fei Fang, Lei Li <br/>
      <!-- <em>arXiv preprint, 2024</em> -->
      <em>Preprint</em>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/ThinkHub.jpg" alt="ThinkHub"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        Learning Personalized Alignment for Evaluating Open-ended Text Generation
        <a href="https://arxiv.org/pdf/2310.03304.pdf"><i class="fa fa-home"></i></a>
      </h4>
      <em><strong>Danqing Wang</strong></em>, Kevin Yang, Hanlin Zhu, Xiaomeng Yang, Andrew Cohen, Lei Li, Yuandong Tian <br/>
      <em>Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2024</em>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/PerSE.jpg" alt="PerSE"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        Learning from Mistakes via Cooperative Study Assistant for Large Language Models 
        <a href="/projects/SALAM/"><i class="fa fa-home"></i></a>
      </h4>
      <em><strong>Danqing Wang</strong></em>, Lei Li <br/>
      <em>Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2023</em>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/SALAM.jpg" alt="SALAM"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        InstructScore: Towards Explainable Text Generation Evaluation with Automatic Feedback
        <!-- <a href="https://leililab.github.io/projects/instructscore/"><i class="fa fa-home"></i></a> -->
        <a href="https://aclanthology.org/2023.emnlp-main.365/"><i class="fa fa-link fa-sm"></i></a>
      </h4>
      Wenda Xu, <em><strong>Danqing Wang</strong></em>, Liangming Pan, Zhenqiao Song, Markus Freitag, William Yang Wang, Lei Li <br/>
      <em>Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2023</em>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/InstructScore2.jpg" alt="Instructscore"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers
        <a href="https://arxiv.org/pdf/2305.14591"><i class="fa fa-link fa-sm"></i></a>
        <!-- <a href="https://leililab.github.io/projects/algo/"><i class="fa fa-home"></i></a> -->
      </h4>
      Kexun Zhang, <em><strong>Danqing Wang</strong></em>, Jingtao Xia, William Yang Wang, Lei Li <br/>
      <em>Thirty-seventh Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2023</em>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/ALGO.jpg" alt="ATUE"></td>
  </tr>
  </table>
<!-- </details> -->


<h2 id="drug"><i>AI for Science: How to find new drugs and interprete AI-decision?</i></h2>
<!-- <details>
<summary> <i> <ins>How to find new drugs and interprete AI-decision?</ins> </i></summary>  -->
<a href="#" onclick="backToTop()" class="back-to-top">Top &#8648;</a>

<table>
<tr>
  <td width="65%">
    <h4>
      Global Human-guided Counterfactual Explanations for Molecular Properties via Reinforcement Learning
      <a href="https://arxiv.org/abs/2406.13869"><i class="fa fa-link fa-sm"></i></a>
    </h4>
    <em><strong>Danqing Wang*</strong></em>, Antonis Antoniades*, Kha-Dinh Luong, Edwin Zhang, Mert Kosan, Jiachen Li, William Yang Wang, Ambuj Singh, Lei Li <br/>
    <em>30th ACM SIGKDD Conference On Knowledge Discovery and Data Mining (<strong>KDD</strong>), 2024</em>
  </td>
  <td width="35%" align="right" valign="middle"><img src="/assets/images/RLHEX.jpg" alt="RLHEX"></td>
</tr>
<tr>
  <td width="65%">
    <h4>
      On Pre-training Language Model for Antibody
      <a href="/projects/EATLM/"><i class="fa fa-home"></i></a>
    </h4>
    <em><strong>Danqing Wang</strong></em>, Fei Ye, Hao Zhou <br/>
    <em>Eleventh International Conference on Learning Representations (<strong>ICLR</strong>), 2023</em>
    <br/><br/>
  </td>
  <td width="35%" align="right" valign="middle"><img src="/assets/images/EATLM.jpg" alt="ATUE"></td>
</tr>
<tr>
  <td width="65%">
    <h4>
      Accelerating Antimicrobial Peptide Discovery with Latent Structure
      <a href="/projects/LSSAMP"><i class="fa fa-home"></i></a>
    </h4>
    <em><strong>Danqing Wang</strong></em>, Zeyu Wen, Fei Ye, Lei Li, Hao Zhou <br/>
    <em>29th ACM SIGKDD Conference On Knowledge Discovery and Data Mining (<strong>KDD</strong>), 2023</em>
    <br/><br/>
  </td>
  <td width="35%" align="right" valign="middle"><img src="/assets/images/LSSAMP.jpg" alt="LSSAMP"></td>
</tr>
</table>
<!-- </details> -->


<h2 id="summ"><i>Text Summarization: Compression is intelligence! Concise & Faithful & Multilingual</i></h2>
<!-- <details>
<summary> <i><ins>Compression is intelligence! Concise & Faithful & Multilingual</ins></i> </summary> -->
<a href="#" onclick="backToTop()" class="back-to-top">Top &#8648;</a>
  <table>
  <tr>
    <td width="65%">
      <h4>
        Contrastive Aligned Joint Learning for Multilingual Summarization
        <a href="/projects/CALMS"><i class="fa fa-home"></i></a>  
      </h4>
      <em><strong>Danqing Wang</strong></em>, Jiaze Chen, Hao Zhou, Xipeng Qiu, Lei Li  <br/>
      <em>Findings of the 59th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>) , 2021</em>
      <br/><br/>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/CALMS/CALMS.jpg" alt="CALMS"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        CNewSum: A Large-scale Chinese News Summarization Dataset with Human-annotated Adequacy and Deducibility Level
        <a href="/projects/CNewSum"><i class="fa fa-home"></i></a>   
        <br/>
      </h4>
      <em><strong>Danqing Wang</strong></em>, Jiaze Chen, Xianze Wu, Hao Zhou, Lei Li  <br/>
      <em>The 10th CCF International Conference on Natural Language Processing and Chinese Computing (<strong>NLPCC</strong>), 2021</em>
      <br/><br/>
    </td>
    <td width="35%" align="right" valign="middle"><img src="/assets/images/CNewSum/motivation.jpg" alt="CNewSum"></td>
  </tr>
  <tr>
    <td width="70%">
      <h4>
        Heterogeneous Graph Neural Networks for Extractive Document Summarization
        <a href="https://aclanthology.org/2020.acl-main.553"><i class="fa fa-link fa-sm"></i></a>     
        <br/>
      </h4>
      <em><strong>Danqing Wang</strong></em>*, Pengfei Liu*, Yining Zheng, Xipeng Qiu, Xuanjing Huang  <br/>
      <em>The 58th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2020</em>
      <br/><br/>
    </td>
    <td width="35%" align="middle" valign="middle"><img src="/assets/images/HSG.jpg" alt="HSG" style="height:300px;"></td>
  </tr>
  <!-- <tr>
    <td width="65%">
      <h4>
        Enhancing Scientific Papers Summarization with Citation Graph
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17482"><i class="fa fa-link fa-sm"></i></a>
      </h4>
      Chenxin An, Ming Zhong, Yiran Chen, <em><strong>Danqing Wang</strong></em>, Xipeng Qiu, Xuanjing Huang <br/>
      <em>Proceedings of the AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2021</em>
      <br/><br/>
    </td>
    <td width="35%"></td>
  </tr> -->
  <tr>
    <td width="65%">
      <h4>
        Extractive Summarization as Text Matching
        <a href="https://arxiv.org/abs/2004.08795"><i class="fa fa-link fa-sm"></i></a>
      </h4>
      Ming Zhong*, Pengfei Liu*, Yiran Chen, <em><strong>Danqing Wang</strong></em>, Xipeng Qiu, Xuanjing Huang <br/>
      <em>The 58th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2020</em>
      <br/><br/>
    </td>
    <td width="35%"></td>
  </tr>
  <!-- <tr>
    <td width="65%">
      <h4>
        A Closer Look at Data Bias in Neural Extractive Summarization Models
        <a href="https://arxiv.org/abs/1909.13705"><i class="fa fa-link fa-sm"></i></a>
      </h4>
      Ming Zhong*, <em><strong>Danqing Wang</strong></em>*, Pengfei Liu*, Xipeng Qiu, Xuanjing Huang <br/>
      <em>Workshop on New Frontiers in Summarization of EMNLP, 2019</em>
      <br/><br/>
    </td>
    <td width="35%"></td>
  </tr> -->
  <tr>
    <td width="65%">
      <h4>
        Searching for Effective Neural Extractive Summarization: What Works and What's Next
        <a href="https://arxiv.org/abs/1907.03491"><i class="fa fa-link fa-sm"></i></a>
      </h4>
      Ming Zhong*, Pengfei Liu*, <em><strong>Danqing Wang</strong></em>*, Xipeng Qiu, Xuanjing Huang   <br/>
      <em>The 57th Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2019</em>
      <br/><br/>
    </td>
    <td width="35%"></td>
  </tr>
  <tr>
    <td width="65%">
      <h4>
        Exploring Domain Shift in Extractive Text Summarization
        <a href="https://arxiv.org/abs/1908.11664"><i class="fa fa-link fa-sm"></i></a>
      </h4>
      <em><strong>Danqing Wang</strong></em>*, Pengfei Liu*, Ming Zhong, Jie Fu, Xipeng Qiu, Xuanjing Huang   <br/>
      <em>arXiv preprint, 2019</em>
      <br/><br/>
    </td>
    <td width="35%"></td>
  </tr>
  </table>
<!-- </details> -->


<script>
  function backToTop() {
    const main = document.getElementById("site-main");
    main.scrollTop = 0;
  }
</script>

